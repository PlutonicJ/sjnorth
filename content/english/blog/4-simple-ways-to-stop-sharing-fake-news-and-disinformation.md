---
title: "4 Simple Ways To Stop Sharing Fake News and Disinformation"
date: 2020-09-13T10:07:47+06:00
draft: false
toc: true

# post thumb
image: "images/post/blog_SN_2.jpg"

# taxonomies
categories:
  - "Disinformation In Politics"
  - "Election Monitoring"
  - "The Psychology of Disinformation"

author: "Samantha North"

aliases:
  - /4-simple-ways-to-stop-sharing-fake-news-and-disinformation/
---

## Introduction

Fake news, more specifically known as disinformation, is a major problem that shows no sign of going away. If anything, it’s [evolving in new ways](https://www.ft.com/content/55a39e92-8357-11ea-b872-8db45d5f6714) to become more nefarious than before. Elections are always major flashpoints for fake news, and the US presidential election of 2020 is no exception. 

[Many individuals and organizations](https://www.fightingfake.org.uk/fightingfakenews) are working hard to come up with ways to fight fake news and disinformation. In the meantime, ordinary internet users can also do their part to help.

In this post, I’ll discuss four simple ways that you can stop sharing fake news and disinformation.

## 4 Simple Ways To Stop Sharing Fake News and Disinformation

### Break Out Of Dopamine Loops

{{< figure src="/images/post/blog_SN_2a-1-1024x536.jpg" alt="fake news and disinformation" >}}

What is a dopamine loop and how does it relate to fake news and disinformation?

Dopamine is a chemical in the brain that affects functions such as mood, attention and motivation. It also plays a key role in affecting our desire to seek out new things – like information. 

Dopamine loops consist of two parts: wanting and liking. ‘Wanting’ compels you to keep searching for new information, while ‘liking’ is the part that makes you feel satisfied once you find it.

The trouble is, in the dopamine loop, wanting is stronger than liking. This leads to us getting trapped, constantly compelled to seek new information. 

The original designers of social media [knew all about dopamine loops](https://www.hbi.de/en/blog/captology-how-computers-rewire-our-minds-and-why-we-let-them/). They designed the platforms with them in mind, knowing that the loops would keep users hooked on the platform. That would increase the likelihood of users viewing online ads.  

So how does the dopamine loop relate to fake news and disinformation? One major way that we get dopamine hits online is through receiving notifications on social media.

You know, those little red numbers in the top corner of Facebook. Think about how you feel when you open your profile and see a bunch of them waiting for you. You feel good, right? This is dopamine firing in your brain. 

Sharing content with your friends and followers is a great way to get notifications, which gives you even more dopamine. But this is where we find the danger from fake news and disinformation.

When we share to get dopamine hits, we’re less likely to take the time to check whether the information we’re sharing is actually true. After all, we’re constantly in a state of information overload. 

One way to stop spreading fake news and disinformation is to break our addiction to dopamine. It makes us vulnerable. We need to avoid getting stuck in dopamine loops, constantly refreshing our social media apps in the hunt for fresh information and notifications. 

#### Quick ways to break the dopamine loop:

- Turning off your social media notifications altogether
- Switching your device to grayscale mode (making it less likely to produce a dopamine hit)
- Pausing to take a few deep breaths before sharing any content 

But there’s another critical way to stop sharing fake news and disinformation…

### Avoid Heated Arguments Online

{{< figure src="/images/post/blog_SN_2b-1-1024x536.jpg" alt="fake news and disinformation" >}}

The internet is full of trolls. No matter what you say online, it often feels like someone is always ready to attack you for it. Your natural instinct is to strike back. That’s a very human response. But it risks making you more likely to share fake news and disinformation.  

Why? Because arguing online is [another way to get trapped in a dopamine loop](https://samanthanorth.com/disinformation-anticipatory-reward-and-why-we-should-all-quit-feeding-the-trolls/). Your antagonist keeps responding, you keep getting more notifications. You keep arguing back, and the cycle continues.

Often, you’ll share a piece of online content, perhaps a news article, to prove your point and get ‘one up’ on your opponent. When doing so, you probably don’t take the time to fact-check the article. That’s where the danger is. 

What’s more, some online trolls are there deliberately. They’re part of coordinated inauthentic behavior campaigns designed to sow division and hostility around certain topics (usually political ones).

These campaigns usually involve fake news and disinformation too. By arguing with these political trolls, you’re giving them exactly what they want. 

Luckily, there’s an easy way to avoid being drawn into online political arguments. On Twitter, it’s the mute function (either mute conversation, or mute user). On Facebook, you can turn off notifications about a specific post.

These features are great, because they allow you to break out of the dopamine loop and the troll has no idea. They just carry on yelling into the void. Meanwhile, you carry on with your day and remain blissfully unaware.

### Check Your Confirmation Biases

{{< figure src="/images/post/blog_SN_2c-1024x536.jpg" alt="confirmation bias" >}}

Confirmation bias plays a key role in increasing our likelihood of sharing fake news and disinformation. But what exactly is it?

Confirmation bias is our natural tendency to search for, favor and easily believe information [that fits with our existing worldview](https://youarenotsosmart.com/2010/06/23/confirmation-bias/). 

Let’s look at how confirmation bias works in practice. For example, you see a tweet (falsely) claiming that US presidential candidate Joe Biden has dementia.

You’re a Trump supporter and you don’t like Biden. Thanks to confirmation bias, you’re very likely to hit retweet on this tweet without even stopping to question if it’s really true. 

You also know that your Twitter followers (who have similar worldviews) will appreciate your sharing this tweet. They’re likely to give it lots of attention, including retweets and favorites – i.e. plenty of extra dopamine for you. 

However, if you saw a similar tweet questioning Trump’s mental health, it’s far more likely that you’d be skeptical of it. Of course, this works in the other direction too. Confirmation bias is not unique to either end of the political spectrum. 

It’s dangerous, because it makes people automatically believe (and probably share) content that fits their worldviews, without stopping to check its veracity. 

If you really want to stop sharing fake news and disinformation, you have to approach your social media use _**knowing**_ that you have confirmation bias. You have to consciously remind yourself what exactly it is that compels you to share a certain post.

It’s not easy, but it’s a necessary step to help stop sharing fake news and disinformation.

### Consider Content Incentives For Fake News

{{< figure src="/images/post/blog_SN_2d-1024x536.jpg" alt="incentives for fake news" >}}
Finally, I want to discuss the incentives of social media content. Every post and article on the internet has a certain incentive behind it. For many content creators, publishing articles is a way to drive traffic to their websites, to earn money from online ads. This is their main incentive.

But the social media space is noisy, so those articles need to stand out. That’s why you’ll see so many overblown clickbait titles that often bear little relevance to the actual content of the article.

In particular, politics is a highly charged and emotive topic, so it’s often used to catch attention and drive site traffic. That’s how the infamous Macedonian teenagers [made money from pushing pro-Trump fake news](https://nymag.com/intelligencer/2016/11/can-facebook-solve-its-macedonian-fake-news-problem.html) in 2016.

Another incentive in content creation is to push a specific worldview, perhaps on behalf of a foreign government. The Kremlin uses this technique a lot.

Amid the early days of the 2020 pandemic, [I found that Russia-linked news sites were pushing conspiracy theory narratives](https://samanthanorth.com/4-things-ive-learned-from-analysing-russia-aligned-news-sites/) (e.g. the dangers of 5G, Bill Gates as responsible for coronavirus, coronavirus as hoax, etc). These showed up consistently on social media, for example in US and UK based Facebook groups.  

Before sharing something on social media, consider the incentives of its creator. Are you truly happy to help that clickbait website make more ad money, or to help a hostile foreign government promote its worldview to your fellow countrymen?

## Summary

In this article, I presented four simple ways to stop sharing fake news and disinformation. I talked about the following points:

- How to break out of dopamine loops 
- How to avoid heated arguments online 
- Why you should check your confirmation biases
- Why you should consider the incentives of content

Are you doing any of these already? Let us know in the comments.